```

```

```

```
## 三、根据爬取行为进行反爬，通常在爬取步骤上做分析
```
2.1 通过js实现跳转来反爬
反爬原理: js实现页面跳转，无法在源码中获取下一页url
解决办法: 多次抓包获取条状url，分析规律

2.2 通过蜜罐（陷阱）获取爬虫ip（或者代理ip），进行反爬
反爬原理: 在爬虫获取链接进行请求的过程中，爬虫会根据正则，xpath，css等方式进行后续链接的提取，此时服务端可以设置一个陷阱url，会被提取规则获取，但是正常用户无法获取，这样就能有效区分爬虫和正常用户

2.3 通过假数据反爬
反爬原理: 想返回的响应中添加假数据污染数据库，通常假数据不会被正常用户看到
解决方法: 长期运行，核对数据库中数据同实质页面中数据对应情况，如果存在问题/仔细分析响应内容

2.4 
```