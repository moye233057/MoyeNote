## 一、基于身份识别进行反爬
```
1.1 通过headers字段来反爬
  （headers中有很多字段，这些字段都有可能会被对方服务器拿过来进行判断是否为爬虫）
1.1.1 通过headers中的User-Agent字段来反爬
反爬原理: 爬虫默认情况下没有User-Agent,而是使用模块默认设置
解决方法: 请求之前添加User-Agent即可，更好的方式是使用User-Agent池来解决。
1.1.2 通过referer字段或者是其他字段来反爬
反爬原理: 爬虫默认情况下不会带上referer字段，服务器通过判断请求发起的源头，以此判断请求是否合法
解决方法: 添加referer字段
1.1.3 通过cookie来反爬
反爬原理: 通过检测cookies来查看发起请求的用户是否具备相应权限，以此来进行反爬
解决方案: 进行模拟登录，成功获取cookies之后在进行数据爬取

1.2 通过请求参数来反爬
(请求参数的获取方法有很多，想服务器发送请求很多时候需要携带请求参数，通常服务器端可以通过检查请求参数是否正确来判断是否为爬虫)
1.2.1  通过html静态文件中获取请求数据(github登录数据)
反爬原因: 通过增加获取请求参数的难度进行反爬
解决方案: 仔细分析抓包得到的每一个包，搞清楚请求之间的联系
1.2.2 通过发送请求获取请求数据
反爬原因: 通过增加获取请求参数的难度进行反爬
解决方案: 仔细分析抓包得到的每一个包，搞清楚请求之间的联系，搞清楚请求参数的来源
1.2.3 通过js生成请求参数
反爬原理: js生成了请求参数
解决方法: 分析js，观察加密的实现过程，通过js2py获取js的执行结果，或者使用selenium来实现
1.2.4 通过验证码来反爬
反爬原理: 对方服务器通过弹出验证码强制用户浏览行为
解决方法: 打码平台或者是机器学习的方法识别验证码，其中打码平台廉价易用，更值得推荐
```


## 三、基础爬虫行为进行反爬
```
3.1  基于总请求频率或总请求数量（爬虫的请求频率与请求数量远高于普通用户）
3.1.1 通过请求ip/账号单位时间内总请求数量进行反爬
反爬原理: 政策浏览器请求网站，速度不会太空，同一个ip/账号大量请求了对方服务器，有更大的可能性被识别为爬虫
解决方法: 对应的通过购买高质量的ip的方式能够解决问题/购买多个账号
3.1.2 通过同一ip/账号请求之间的间隔进行反爬
反爬原理: 正常人操作浏览器浏览网站，请求直接的时间间隔是随机的，而爬虫前后两个请求之间时间间隔通常比较固定同时时间间隔较短，因此可以用来做反爬
解决方法: 请求之间随机等待，模拟真实用户操作，在添加时间间隔后，为了能够高速获取数据，尽量使用代理池，如果是账号，则将账号请求之间设置随机休眠

3.2  根据爬取行为进行反爬，通常在爬取步骤上做分析
3.2.1 通过js实现跳转来反爬
反爬原理: js实现页面跳转，无法在源码中获取下一页url
解决办法: 多次抓包获取条状url，分析规律
3.2.2 通过蜜罐（陷阱）获取爬虫ip（或者代理ip），进行反爬
反爬原理: 在爬虫获取链接进行请求的过程中，爬虫会根据正则，xpath，css等方式进行后续链接的提取，此时服务端可以设置一个陷阱url，会被提取规则获取，但是正常用户无法获取，这样就能有效区分爬虫和正常用户
3.2.3 通过假数据反爬
反爬原理: 想返回的响应中添加假数据污染数据库，通常假数据不会被正常用户看到
解决方法: 长期运行，核对数据库中数据同实质页面中数据对应情况，如果存在问题/仔细分析响应内容
3.2.4 阻塞任务队列
反爬原理: 通过生成大量垃圾url，从而阻塞任务队列，降低爬虫的实际工作效率
解决方法: 观察运行过程中请求响应状态/仔细分析源码获取垃圾url生成规则，对URL进行过滤
3.2.5 阻塞网络IO
反爬原理: 发送请求获取相应的过程实际上就是下载过程，在任务队列中混入一个大文件url，当爬虫在进行该请求时将会占用网络io，如果是多线程则会占用线程
解决方法: 观察爬虫运行状态/多线程对请求线程时/发送请求线程时的状态
3.6 运维平台综合审计
反爬原理: 通过运维平台进行综合管理，通常采用复合型反爬虫策略，多种手段同时使用
解决方法: 仔细观察分析，长期运行测试目标网站，检查数据采集速度，多方面处理
```

## 四、基于数据加密进行反爬
```
3 对响应中含有的数据进行特殊化处理
  (通常的特殊化处理主要指的就是css数据偏移/自定义字体/数据加密/数据图片/特殊编码格式等)
3.1  通过自定义字体来反爬
反爬思路: 使用自有字体文件(浏览器F12会显示正方形乱码框)
解决思路: 切换手机版/解析字体文件进行翻译
3.2  通过css来反爬
反爬思路: 源码数据不为真正数据，需要通过css位移才能参数真正数据
解决思路: 计算css的偏移
3.3  通过js动态生成数据进行反爬
反爬原理: 通过js动态生成
解决思路: 解析关键js，获得数据生成流程，模拟生成数据
3.4  通过数据图片化反爬
例如: 58同城短租
解决思路: 通过使用图片解析引擎从图片中解析数据
3.5  通过编码格式进行反爬
反爬原理: 不适用默认编码格式，在获取响应之后通常爬虫适用utf-8进行解码，此时解码结果将会是乱码或者报错
解决思路: 根据源码进行多格式解码，或者真正的解码格式
```